{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saikatb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import re  \n",
    "import nltk  \n",
    "nltk.download('stopwords')  \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('OnePlus6T.labelled-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phone is simply superb in all aspects</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low light performance of the camera is outstan...</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you simply cannot go wrong with this phone</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i got this phone on friday evening</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pros: great battery life amazing performance p...</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews   intent\n",
       "0              phone is simply superb in all aspects  product\n",
       "1  low light performance of the camera is outstan...  product\n",
       "2         you simply cannot go wrong with this phone  product\n",
       "3                 i got this phone on friday evening  product\n",
       "4  pros: great battery life amazing performance p...  product"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.reviews\n",
    "y = data.intent.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'delivery', 1: 'product', 2: 'seller'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict( enumerate(y.cat.categories) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for sen in range(0, len(X)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # remove all digits\n",
    "    document = re.sub(r'\\d+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [lemmatizer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "vectorizer = CountVectorizer(max_features=100, min_df=3, max_df=0.7, stop_words=stopwords.words('english'))  \n",
    "X = vectorizer.fit_transform(documents).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "tfidfconverter = TfidfTransformer()  \n",
    "X = tfidfconverter.fit_transform(X).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res_test, y_res_test = sm.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_report(model):\n",
    "    model.fit(X_res, y_res)\n",
    "    scores = cross_val_score(model, X_res, y_res, cv=10)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred = cross_val_predict(model, X_res_test, y_res_test, cv=10) #clf3.predict(X_test)  \n",
    "\n",
    "    print(accuracy_score(y_res_test, y_pred)) \n",
    "    print(metrics.classification_report(y_res_test, y_pred,target_names=['delivery','product','seller']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, text):\n",
    "    model.fit(X_res, y_res)\n",
    "    documents = []\n",
    "\n",
    "    for sen in range(0, len([text])):  \n",
    "        # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str([text][sen]))\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # remove all digits\n",
    "        document = re.sub(r'\\d+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Lemmatization\n",
    "        document = document.split()\n",
    "\n",
    "        document = [lemmatizer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        documents.append(document)\n",
    "    vectorizer = CountVectorizer(max_features=100, stop_words=stopwords.words('english'))  \n",
    "    X = vectorizer.fit_transform(documents).toarray() \n",
    "    tfidfconverter = TfidfTransformer()  \n",
    "    X = tfidfconverter.fit_transform(X).toarray()\n",
    "    X_test = np.zeros(100)\n",
    "    for i,d in enumerate(X[0]):\n",
    "        X_test[i] = d\n",
    "    return model.predict([X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8484848484848485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    delivery       0.76      0.86      0.81        44\n",
      "     product       0.84      0.82      0.83        44\n",
      "      seller       0.97      0.86      0.92        44\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       132\n",
      "   macro avg       0.86      0.85      0.85       132\n",
      "weighted avg       0.86      0.85      0.85       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "clf1 = SVC(C=5.0, gamma='auto', kernel='rbf')\n",
    "predict_report(clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257575757575758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    delivery       0.76      1.00      0.86        44\n",
      "     product       1.00      0.59      0.74        44\n",
      "      seller       0.81      0.89      0.85        44\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       132\n",
      "   macro avg       0.86      0.83      0.82       132\n",
      "weighted avg       0.86      0.83      0.82       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "clf2 = MultinomialNB()\n",
    "predict_report(clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939393939393939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    delivery       0.93      0.93      0.93        44\n",
      "     product       0.84      0.86      0.85        44\n",
      "      seller       0.91      0.89      0.90        44\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       132\n",
      "   macro avg       0.89      0.89      0.89       132\n",
      "weighted avg       0.89      0.89      0.89       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier()\n",
    "predict_report(clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257575757575758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    delivery       0.76      0.86      0.81        44\n",
      "     product       0.79      0.70      0.75        44\n",
      "      seller       0.93      0.91      0.92        44\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       132\n",
      "   macro avg       0.83      0.83      0.83       132\n",
      "weighted avg       0.83      0.83      0.83       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf4 = KNeighborsClassifier(n_neighbors=5)\n",
    "predict_report(clf4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
